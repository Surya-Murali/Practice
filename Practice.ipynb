{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "features = [[10,1], [15,1], [100,0], [120,0]]\n",
    "labels = [0,0,1,1]\n",
    "clf= tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features, labels)\n",
    "print (clf.predict([[150, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c5cfd5e470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "greyhounds = 500\n",
    "labs = 500\n",
    "\n",
    "grey_height = 28 + 4*np.random.randn(greyhounds)\n",
    "lab_height = 24 + 4*np.random.randn(labs)\n",
    "\n",
    "plt.hist([grey_height, lab_height], stacked = True, color = ['r', 'b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[-1.01266886]\n",
      "[-0.07975737  0.00482917]\n",
      "[-7.04785585 -0.6744918   3.05344309]\n",
      "[ 32.22957828  37.50154156  29.39266456]\n",
      "500\n",
      "[ 24.79738312  18.47138941  36.10754439  23.10682929  30.46826411\n",
      "  28.31484922  31.43399001  26.78910012  28.92794197  20.78025796\n",
      "  26.00273979  34.15723328  26.20094181  23.29568848  24.47044047\n",
      "  28.11032481  29.33693005  34.22708474  29.37054865  31.22722065\n",
      "  26.56069713  25.32697718  24.69848199  29.89847864  35.55269685\n",
      "  31.27459647  26.02718256  22.96971788  31.26949992  28.87572782\n",
      "  24.6472203   24.39658113  31.24146587  30.62836067  31.12289197\n",
      "  29.52392928  29.44717329  22.80955319  28.79636241  28.6379574\n",
      "  25.93124043  30.20932552  27.14417641  36.32714277  27.67616057\n",
      "  27.0839787   26.13944651  27.52678086  29.98369373  31.42307685\n",
      "  25.58738215  25.56532211  32.96829091  29.96020255  22.88916947\n",
      "  29.28843722  31.61855717  29.60518523  34.52540973  23.10793157\n",
      "  26.26589012  23.49615925  24.46794131  26.17247714  23.83428395\n",
      "  27.45457307  28.94404081  25.35010111  23.53842408  20.11207569\n",
      "  29.38102375  25.80237497  33.16664041  24.55843858  31.52730048\n",
      "  23.77970608  23.81295299  30.39049006  25.00236831  26.14362698\n",
      "  28.18192284  26.82620801  29.05614741  28.37537037  29.87121598\n",
      "  26.36006269  27.68488429  34.95616217  35.47212248  22.17782127\n",
      "  25.61596688  27.41847079  27.10625799  33.92338322  29.51421039\n",
      "  31.60433659  31.41412184  27.87826855  34.28278536  33.29375421\n",
      "  27.2966134   24.47064154  32.13374852  22.67836827  27.917398\n",
      "  21.23630488  28.0889285   28.84149082  24.7036853   30.93930409\n",
      "  30.53052607  28.75783725  16.68853149  26.42559627  25.73381639\n",
      "  27.34997331  27.38656075  30.51798329  20.52099826  26.41503026\n",
      "  28.9899217   30.02424985  32.23289085  31.04354008  23.12227538\n",
      "  25.26466291  30.67486929  24.57082953  25.11063886  29.1062278\n",
      "  24.28152944  27.58336512  32.12590971  27.56286143  33.22788327\n",
      "  35.29028504  31.57990884  18.98272157  32.93448329  27.40242251\n",
      "  24.79589446  26.8972004   35.4029701   31.23071817  23.72038375\n",
      "  26.32703805  31.0928266   23.91339145  22.72992048  25.31201299\n",
      "  18.79522524  25.3597267   29.90512156  32.12379557  29.11649358\n",
      "  23.8258454   24.13974497  27.82650359  25.68082305  30.45230267\n",
      "  27.09696913  29.62943737  29.09401458  25.34778709  33.59073367\n",
      "  30.66401869  31.52566169  26.36907044  21.22319152  32.06339569\n",
      "  31.26002119  26.2346327   34.66567574  22.4463841   33.64648583\n",
      "  37.93672436  26.85672663  26.89763567  24.25580318  36.72792518\n",
      "  24.4127334   27.61206068  32.75883747  30.31326708  38.60465278\n",
      "  27.70752868  25.93913184  36.21213431  26.02011151  26.68330803\n",
      "  31.30144979  25.10095376  30.30685118  31.24096179  28.97096171\n",
      "  29.3693172   27.54503253  34.31507112  31.2411281   26.0661876\n",
      "  20.11772242  27.1189282   22.44060292  28.88914645  22.09259267\n",
      "  24.32180304  28.68504867  22.64806293  33.44857282  30.76143241\n",
      "  32.48440377  29.96664453  23.55448109  22.25564207  29.77297989\n",
      "  25.64235926  28.69842115  27.79459913  24.00886536  36.29120095\n",
      "  23.10307295  28.53328401  24.13789194  36.16124373  31.06127024\n",
      "  23.93290493  26.7911492   26.84034096  30.56362996  32.50125253\n",
      "  30.93630779  25.06426327  26.00315518  26.85717325  24.89897629\n",
      "  27.14198919  32.23415311  30.28013048  27.38513838  25.16751615\n",
      "  27.88161458  20.99620079  24.08964447  27.57707835  31.05773124\n",
      "  24.55602457  28.73043881  29.04764672  29.06584445  25.88346695\n",
      "  32.41119203  29.59228383  26.87248095  24.07783951  28.03032973\n",
      "  32.25459625  33.63923691  23.97055701  28.94920772  23.66440821\n",
      "  26.66767327  29.65906535  36.44904479  26.66648982  22.69020234\n",
      "  29.83917427  20.97653862  24.30704683  31.24386209  23.50927634\n",
      "  31.73689057  27.46118921  26.73048415  31.54056738  26.54298721\n",
      "  28.91895872  35.97330933  29.42653559  31.47081886  31.7261444\n",
      "  30.6759611   35.38881565  30.54355854  21.64343781  23.0972746\n",
      "  25.9764041   29.08737597  28.93097258  36.74959775  28.99890339\n",
      "  23.41545752  32.20330259  26.25864686  29.247323    27.3087314\n",
      "  26.98697183  28.16059566  35.26934286  28.04670491  19.13264095\n",
      "  28.24881899  27.74287183  30.75660652  20.86476714  26.92356064\n",
      "  32.81069632  26.54270133  29.53041489  24.3774582   33.91446211\n",
      "  30.720076    27.42058928  23.6109133   28.44958135  32.77367264\n",
      "  25.70864453  27.14419401  28.81710358  27.97370662  24.59081289\n",
      "  26.67253814  24.49409534  24.24434575  23.62385433  25.81185137\n",
      "  28.0085876   28.67444368  25.41813749  27.62003172  24.49347983\n",
      "  27.43102303  29.13538975  25.94001663  33.05161995  26.72711482\n",
      "  37.03526446  24.86518688  28.20023103  36.5908015   27.60405747\n",
      "  24.86882887  26.0929685   22.49369629  33.70898734  29.01278984\n",
      "  35.57341875  28.93000475  26.95439005  24.53933633  27.14318314\n",
      "  28.72064939  28.32104023  27.65515114  23.63295447  33.83461483\n",
      "  32.60259257  28.58135783  18.70972704  24.91501102  22.84816544\n",
      "  22.4401143   26.23606704  28.69914499  23.7219539   40.57597308\n",
      "  27.33261841  32.28782419  29.1662937   29.14716375  26.92037846\n",
      "  23.01301132  23.38214632  26.83158007  28.97876074  28.11040531\n",
      "  26.77026787  25.73641615  29.00549603  23.1346116   26.6673818\n",
      "  23.01318046  34.88893474  26.18330098  28.16439838  24.06510198\n",
      "  27.10937787  31.05974775  24.01166058  32.79607258  26.74641965\n",
      "  32.86062759  26.03213232  35.71852324  28.49763643  35.2200754\n",
      "  28.92058055  25.03182463  28.09233185  25.58465879  26.46443836\n",
      "  27.64587333  28.97187692  21.61539363  32.87065864  29.89546786\n",
      "  27.8129652   30.23592549  31.87602734  25.82255722  29.01684959\n",
      "  27.09437429  26.52130567  26.77729603  24.5361512   31.7622747\n",
      "  23.26488755  32.07615666  25.61817326  29.49847002  21.84186184\n",
      "  30.6178291   24.91512737  26.23293286  36.12395714  27.56463841\n",
      "  30.2856841   32.34459637  29.43041728  24.31385456  28.95949379\n",
      "  30.03654884  26.16840428  37.49959956  29.78616885  31.12876096\n",
      "  32.9136289   25.54620686  30.69957378  21.57674786  31.54548274\n",
      "  23.57064102  26.21531611  25.97610372  25.71381589  26.60834067\n",
      "  35.56371726  21.33542619  24.65386124  23.16783448  31.89069556\n",
      "  27.81043879  29.54576725  31.66233645  25.71252678  31.08537607\n",
      "  25.96692903  35.0670969   32.87154654  31.42377311  29.53696662\n",
      "  33.46736391  23.7629769   30.47956271  23.01210032  30.73519033\n",
      "  33.75804922  30.33956063  33.59271773  19.72017688  29.84437012\n",
      "  28.17665281  27.77987265  30.49616374  30.79040478  34.18033691\n",
      "  34.44887122  28.29273762  25.59572101  27.21017829  30.78687249\n",
      "  29.76559856  32.01853955  30.2492193   29.25403929  28.31429947\n",
      "  28.05465037  25.03145689  24.87302417  20.82531749  25.67881165\n",
      "  30.30709132  22.70983006  32.69429645  36.25590613  24.58475643\n",
      "  28.83771412  34.76796467  28.73871061  30.30717685  35.36887669]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/g9ZAH/w5oNy6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246b2122cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "greyhounds = 500\n",
    "labs = 500\n",
    "\n",
    "print(np.random.randn(0))\n",
    "print(np.random.randn(1))\n",
    "print(np.random.randn(2))\n",
    "print(4*np.random.randn(3))\n",
    "print(28 + 4*np.random.randn(3))\n",
    "print(greyhounds)\n",
    "print(28 + 4*np.random.randn(greyhounds))\n",
    "\n",
    "grey_height = 28 + 4*np.random.randn(greyhounds)\n",
    "lab_height = 24 + 4*np.random.randn(labs)\n",
    "\n",
    "plt.hist([grey_height, lab_height], stacked = True, color = ['r', 'b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXpKa+38zWdAOeOE/EAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246b53adef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "greyhounds = 500\n",
    "labs = 500\n",
    "\n",
    "grey_height = 28 + 4*np.random.randn(greyhounds)\n",
    "lab_height = 24 + 4*np.random.randn(labs)\n",
    "\n",
    "plt.hist([grey_height, lab_height], stacked = True, color = ['r', 'b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_classifier = KNeighborsClassifier()\n",
    "\n",
    "my_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions = my_classifier.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(y_test, predictions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def euc(a,b):\n",
    "    return distance.euclidean(a,b)\n",
    "\n",
    "#KNN: Nearest Neighbor algorithm\n",
    "# Creating class for our own classifier\n",
    "class myClassifier():\n",
    "    #methods inside the class\n",
    "    def fit(self, x_train, y_train):\n",
    "    \n",
    "        #store training data in class\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        #Predictions is a 2D array\n",
    "        predictions = []\n",
    "        for row in x_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "    def closest(self, row):\n",
    "        best_dist = euc(row, self.x_train[0])\n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.x_train)):\n",
    "            dist = euc(row, self.x_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = i\n",
    "        return self.y_train[best_index]\n",
    "    \n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5)\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#my_classifier = KNeighborsClassifier()\n",
    "my_classifier = myClassifier()\n",
    "\n",
    "my_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions = my_classifier.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(y_test, predictions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def euc(a,b):\n",
    "    return distance.euclidean(a,b)\n",
    "\n",
    "class myfirstClassifier():\n",
    "    #methods inside the class\n",
    "    # fit - input : features & labels\n",
    "    #store training data in class\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    #Predictions is a 2D array\n",
    "    #Predictions - input: features \n",
    "    def predict(self, x_test):\n",
    "        predictions = []\n",
    "        for row in x_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "    def closest(self, row):\n",
    "        best_dist = euc(row, self.x_train[0])\n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.x_train)):\n",
    "            dist = euc(row, self.x_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = i\n",
    "        #print (best_dist)\n",
    "        #print (best_index)\n",
    "        return self.y_train[best_index]\n",
    "    \n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5)\n",
    "\n",
    "\n",
    "my_classifier = myfirstClassifier()\n",
    "\n",
    "my_classifier.fit(x_train, y_train)\n",
    "predictions = my_classifier.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(y_test, predictions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "# Pop up appears. Download 'All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am Surya.', 'John Cena is the best.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "a_text = \"I am Surya. John Cena is the best.\"\n",
    "print (sent_tokenize(a_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'Surya', '.', 'John', 'Cena', 'is', 'the', 'best', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "a_text = \"I am Surya. John Cena is the best.\"\n",
    "print (word_tokenize(a_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'Surya', '.', 'John', 'Cena', 'is', 'the', 'best', '.']\n",
      "I\n",
      "am\n",
      "Surya\n",
      ".\n",
      "John\n",
      "Cena\n",
      "is\n",
      "the\n",
      "best\n",
      ".\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "count = 0\n",
    "myText = \"I am Surya. John Cena is the best.\"\n",
    "print (word_tokenize(myText))\n",
    "for i in word_tokenize(myText):\n",
    "    count = count+1\n",
    "    print (i)\n",
    "print (count)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "count = 0\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "words = word_tokenize(myText)\n",
    "#print (words);\n",
    "#print (pos_tag(words));\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "tree.pprint()\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Very/RB\n",
      "  thorough/JJ\n",
      "  and/CC\n",
      "  took/VBD\n",
      "  time/NN\n",
      "  to/TO\n",
      "  talk/VB\n",
      "  to/TO\n",
      "  me/PRP\n",
      "  about/IN\n",
      "  my/PRP$\n",
      "  problem/NN\n",
      "  ./.\n",
      "  I/PRP\n",
      "  would/MD\n",
      "  highly/RB\n",
      "  recommend/VB\n",
      "  this/DT\n",
      "  doctor/NN)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "count = 0\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "words = word_tokenize(myText)\n",
    "#print (words);\n",
    "#print (pos_tag(words));\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "tree.pprint()\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ha': 3, 'really': 2, 'that': 1, 'was': 1, 'funny': 1})\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from collections import Counter\n",
    "count = 0\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "myText2 = \"Ha ha ha that was really really funny\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText2.lower())\n",
    "#print (words);\n",
    "#print (pos_tag(words));\n",
    "\n",
    "#def chunkWords(text):\n",
    "#    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "#tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "print (frequencies);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hahah', 'ha', 'ha', 'that', 'wa', 'realli', 'realli', 'realis', 'realis', 'funni', '.', 'haha', 'cours', 'cours']\n",
      "Counter({'ha': 2, 'realli': 2, 'realis': 2, 'cours': 2, 'hahah': 1, 'that': 1, 'wa': 1, 'funni': 1, '.': 1, 'haha': 1})\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "myText2 = \"Hahah ha ha that was really really realised realise funny. Haha course courses\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText2.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "print (stemmedFrequencies);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ha': 2, 'realli': 2, 'realis': 2, 'cours': 2, 'hahah': 1, 'that': 1, 'wa': 1, 'funni': 1, '.': 1, 'haha': 1})\n",
      "ha 2\n",
      "realli 2\n",
      "realis 2\n",
      "cours 2\n",
      "hahah 1\n",
      "that 1\n",
      "wa 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "englishStopwords = stopwords.words('english')\n",
    "\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "myText2 = \"Hahah ha ha that was really really realised realise funny. Haha course courses\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText2.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "#print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "print (stemmedFrequencies);\n",
    "\n",
    "for i, count in stemmedFrequencies.most_common(7):\n",
    "    print (i, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ha': 2, 'realli': 2, 'realis': 2, 'cours': 2, 'hahah': 1, 'that': 1, 'wa': 1, 'wow': 1, 'woww': 1, 'funni': 1, '.': 1, 'haha': 1})\n",
      "ha 2\n",
      "realli 2\n",
      "realis 2\n",
      "cours 2\n",
      "hahah 1\n",
      "wa 1\n",
      "wow 1\n",
      "woww 1\n",
      "funni 1\n",
      "haha 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "englishStopwords = stopwords.words('english')\n",
    "\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "myText2 = \"Hahah ha ha that was really wow really woww realised realise funny. Haha course courses\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText2.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "#print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "print (stemmedFrequencies);\n",
    "\n",
    "for i, count in stemmedFrequencies.most_common(20):\n",
    "    if i in englishStopwords or len(i)<2:\n",
    "        continue\n",
    "    print (i, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.': 5, 'he': 3, 'is': 3, 'wow': 2, 'that': 2, 'wa': 2, 'veri': 2, 'thought': 1, 'nice': 1, 'a': 1, 'good': 1, 'person': 1, 'rude': 1, 'awesom': 1})\n",
      "('he', 'is') 3\n",
      "('that', 'was') 2\n",
      "('wow', 'wow') 1\n",
      "('wow', 'that') 1\n",
      "('was', 'very') 1\n",
      "('very', 'very') 1\n",
      "('very', 'thoughtful') 1\n",
      "('was', 'nice') 1\n",
      "('is', 'a') 1\n",
      "('a', 'good') 1\n",
      "('good', 'person') 1\n",
      "('is', 'rude') 1\n",
      "('is', 'awesome') 1\n",
      "['wow', 'wow', 'that', 'was', 'very', 'very', 'thoughtful', '.', 'that', 'was', 'nice', '.', 'he', 'is', 'a', 'good', 'person', '.', 'he', 'is', 'rude', '.', 'he', 'is', 'awesome', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "englishStopwords = stopwords.words('english')\n",
    "\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "myText2 = \"Wow wow that was very very thoughtful. That was nice. He is a good person. He is rude. He is awesome.\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText2.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "bigramsList = []\n",
    "\n",
    "\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "#print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "print (stemmedFrequencies);\n",
    "\n",
    "bigrams = list(ngrams(words2, 2))\n",
    "bigramsList = bigramsList + bigrams\n",
    "\n",
    "frequencies = Counter(bigramsList)\n",
    "for i, count in frequencies.most_common(20):\n",
    "    if(\".\" in i):\n",
    "        continue\n",
    "    print (i, count)\n",
    "    \n",
    "print (words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('very', 'thorough', 'and') 1\n",
      "('thorough', 'and', 'took') 1\n",
      "('and', 'took', 'time') 1\n",
      "('took', 'time', 'to') 1\n",
      "('time', 'to', 'talk') 1\n",
      "('to', 'talk', 'to') 1\n",
      "('talk', 'to', 'me') 1\n",
      "('to', 'me', 'about') 1\n",
      "('me', 'about', 'my') 1\n",
      "('about', 'my', 'problem') 1\n",
      "('i', 'would', 'highly') 1\n",
      "('would', 'highly', 'recommend') 1\n",
      "('highly', 'recommend', 'this') 1\n",
      "('recommend', 'this', 'doctor') 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "englishStopwords = stopwords.words('english')\n",
    "\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText1.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "bigramsList = []\n",
    "\n",
    "\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "#print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "#print (stemmedFrequencies);\n",
    "\n",
    "bigrams = list(ngrams(words2, 3))\n",
    "bigramsList = bigramsList + bigrams\n",
    "\n",
    "frequencies = Counter(bigramsList)\n",
    "for i, count in frequencies.most_common(20):\n",
    "    if(\".\" in i or \",\" in i):\n",
    "        continue\n",
    "    print (i, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('very', 'thorough', 'and') 1\n",
      "('thorough', 'and', 'took') 1\n",
      "('and', 'took', 'time') 1\n",
      "('took', 'time', 'to') 1\n",
      "('time', 'to', 'talk') 1\n",
      "('to', 'talk', 'to') 1\n",
      "('talk', 'to', 'me') 1\n",
      "('to', 'me', 'about') 1\n",
      "('me', 'about', 'my') 1\n",
      "('about', 'my', 'problem') 1\n",
      "('i', 'would', 'highly') 1\n",
      "('would', 'highly', 'recommend') 1\n",
      "('highly', 'recommend', 'this') 1\n",
      "('recommend', 'this', 'doctor') 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "count = 0\n",
    "stemmer = PorterStemmer()\n",
    "englishStopwords = stopwords.words('english')\n",
    "\n",
    "myText = \"I am Surya Murali. John Cena is the best.\"\n",
    "myText1 = \"Very thorough and took time to talk to me about my problem. I would highly recommend this doctor\"\n",
    "words = word_tokenize(myText)\n",
    "words1 = word_tokenize(myText1)\n",
    "words2 = word_tokenize(myText1.lower())\n",
    "\n",
    "def chunkWords(text):\n",
    "    return(ne_chunk(pos_tag(word_tokenize(text))))\n",
    "#print (chunkWords(myText));\n",
    "\n",
    "tree = chunkWords(myText1);\n",
    "#tree.pprint()\n",
    "#tree.draw()\n",
    "\n",
    "frequencies = Counter(words2)\n",
    "#print (frequencies);\n",
    "\n",
    "stemmedWordList = []\n",
    "bigramsList = []\n",
    "\n",
    "\n",
    "for i in words2:\n",
    "    stemmedWord = stemmer.stem(i)\n",
    "    stemmedWordList.append(stemmedWord)\n",
    "#print(stemmedWordList)   \n",
    "\n",
    "stemmedFrequencies = Counter(stemmedWordList)\n",
    "#print (stemmedFrequencies);\n",
    "\n",
    "bigrams = list(ngrams(words2, 3))\n",
    "bigramsList = bigramsList + bigrams\n",
    "\n",
    "frequencies = Counter(bigramsList)\n",
    "for i, count in frequencies.most_common(20):\n",
    "    if(\".\" in i or \",\" in i):\n",
    "        continue\n",
    "    print (i, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
